{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/worldwidekatie/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVfaLrjLvxvQ"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Neural Networks\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 1*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wxtoY12mwmih"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### **Input Layer:** The input layer is the nodes that represent the data you put into it, like the features or a bias.\n",
        "\n",
        "### **Hidden Layer:** Hidden layers are the nodes that are hidden from us but it's where the magic happens. It's like the neurons with the different functions that pass information to each other to eventually come to a decision.\n",
        "\n",
        "\n",
        "### **Output Layer:** This is the node(s) of output, like predictions, prediction probability, recommendations, etc.\n",
        "\n",
        "\n",
        "### **Neuron:** The neurons are the individual nodes.\n",
        "\n",
        "\n",
        "### **Weight:** The weights are the neural network equivalent to coefficients and determine how it precdits stuff given different feature values.\n",
        "\n",
        "\n",
        "### **Activation Function:** Activation function is the control valve for the neurons that controls how much information flows between neurons, whether a cell fires and how much it functions.\n",
        "\n",
        "\n",
        "### **Node Map:** Node maps are a visual diagram of the architecture of neural networks. It's like a flow chart with input, output, and hidden layers.\n",
        "\n",
        "\n",
        "### **Perceptron:** TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NXuy9WcWzxa4"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PlSwIJMC0A8F"
      },
      "source": [
        "We begin with the input layer consisting of the input or feature nodes and perhaps a bias, which is the neural network equivalent of an intercept to start you off. It then moves through the hidden layer nodes and their weights according to the instructions from the activation function. It ends on the output layer, which is the nodes representing the output of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sWR43PTwhSk"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AnkksXP8SGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = { 'x1': [0,1,0,1],\n",
        "         'x2': [0,0,1,1],\n",
        "         'y':  [1,1,1,0]\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fxSCCH6PdvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = ['x1', 'x2']\n",
        "output = 'y'\n",
        "\n",
        "X_train = np.array(df[inputs])\n",
        "Y_train = tuple(df[output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJiB8K57qftJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab01ba93-71b2-4a87-8701-dd950bf2f7dc"
      },
      "source": [
        "y_train = []\n",
        "for i in Y_train:\n",
        "  y_train.append([i])\n",
        "\n",
        "y_train = tuple(y_train)\n",
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1], [1], [1], [0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sgh7VFGwnXGH",
        "colab": {}
      },
      "source": [
        "#make sigmoid functions\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def sigmoid_der(x):\n",
        "  sx = sigmoid(x)\n",
        "  return sx*(1-sx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc0zj4Kr8SGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1f6dcbe8-34aa-4fce-8b4e-335c88d3a273"
      },
      "source": [
        "# Make random weights. \n",
        "import numpy as np\n",
        "\n",
        "weights = 2*np.random.random((2,1))-1\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.66174444],\n",
              "       [-0.11881769]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81ipiWlNp-mL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5f823617-0e0d-47fc-91e0-a86564726d7a"
      },
      "source": [
        "# calculate weighted sum of inputs and weights\n",
        "weighted_sum = np.dot(X_train, weights)\n",
        "weighted_sum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ],\n",
              "       [-0.66174444],\n",
              "       [-0.11881769],\n",
              "       [-0.78056212]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76-V94v2p-5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d731a307-d3d7-4abe-b78d-fb9ea92e1cbe"
      },
      "source": [
        "# output the activated value for the end of 1 training epoch\n",
        "y_pred = np.array(sigmoid(weighted_sum))\n",
        "y_pred\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5       ],\n",
              "       [0.34034786],\n",
              "       [0.47033048],\n",
              "       [0.31419875]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHG-IHr7rPvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "30151ffd-cd91-4f58-83a2-28e7f8244bb9"
      },
      "source": [
        "# take difference of output and true values to calcuate error\n",
        "error = y_train - y_pred\n",
        "error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.5       ],\n",
              "       [ 0.65965214],\n",
              "       [ 0.52966952],\n",
              "       [-0.31419875]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QonhICsvrPsL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "91343453-6480-4df9-e4b3-b816f7c966e1"
      },
      "source": [
        "# do gradient descent iterative updating of weights\n",
        "\n",
        "adjustments = error * sigmoid_der(weighted_sum)\n",
        "adjustments"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.125     ],\n",
              "       [ 0.14809929],\n",
              "       [ 0.13195112],\n",
              "       [-0.06770288]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybcW366LrPl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "47a6bd7c-561b-4b7d-f97a-35f8ca0e853b"
      },
      "source": [
        "# adjusted weights\n",
        "weights = np.dot(X_train.T, adjustments)\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0803964 ],\n",
              "       [0.06424824]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3itbCpUptUof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "2f9e0d57-6bfe-4c9c-cff2-5463b9ccdc87"
      },
      "source": [
        "# update weights 10,000 times\n",
        "\n",
        "for iteration in range(10000):\n",
        "\n",
        "  # weighted sum of inputs/weights\n",
        "  weighted_sum = np.dot(X_train, weights)\n",
        "\n",
        "  # activate\n",
        "  activated_output = sigmoid(weighted_sum)\n",
        "\n",
        "  # cac error\n",
        "  error = y_train - activated_output\n",
        "  adjustments = error*sigmoid_der(weighted_sum)\n",
        "\n",
        "  #update weights\n",
        "  weights += np.dot(X_train.T, adjustments)\n",
        "\n",
        "print(\"weights after training\")\n",
        "print(weights)\n",
        "print(\" \")\n",
        "print(\"Output after training\")\n",
        "print(activated_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights after training\n",
            "[[ 1.52655666e-16]\n",
            " [-3.05311332e-16]]\n",
            " \n",
            "Output after training\n",
            "[[0.5]\n",
            " [0.5]\n",
            " [0.5]\n",
            " [0.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTmmiehYaPR0",
        "colab_type": "text"
      },
      "source": [
        "That's pretty darn awful. I'm gonna make the class thing and see if that does any better.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xf7sdqVs0s4x"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt0JwAlqOkEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc4wOzpq8SGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7aa9643e-4a5a-4245-be57-d3a1db5262f2"
      },
      "source": [
        "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
        "diabetes.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpEp1xF_8SG6",
        "colab_type": "text"
      },
      "source": [
        "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvnQIeES8SG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO if I have time to come back and figure it out\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "feats = list(diabetes)[:-1]\n",
        "\n",
        "X = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdVNBpfYJ7-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making it smaller to test stuff out quicker\n",
        "df = diabetes.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J9YDQJcNztk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0fad8196-8855-4704-d8bd-f0aa081e830e"
      },
      "source": [
        "diabetes.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbrehTrh1aKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
        "       'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
        "target = df['Outcome']\n",
        "\n",
        "input = np.array(features)\n",
        "output = tuple(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ud2GgCVpPLCQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fef3a68-c815-4866-b7de-7d3a3265a5bc"
      },
      "source": [
        "class Perceptron(object):\n",
        "    X = None\n",
        "    y = None\n",
        "    niter = None\n",
        "    #np.random.seed(812)\n",
        "    \n",
        "    def __init__(self, a, b, niter=1000, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.a = a\n",
        "        self.b = b\n",
        "        self.niter = niter\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "      \n",
        "    def sigmoid_derivative(self, x):\n",
        "        sx = self.sigmoid(x)\n",
        "        return sx * (1-sx)\n",
        "\n",
        "    def fit(self):\n",
        "      a = self.a\n",
        "      b = self.b\n",
        "      z = len(a[0])\n",
        "      weights = 2 * np.random.random((z,1)) -1\n",
        "\n",
        "      if type(b[0]) == int:\n",
        "        var = []\n",
        "        for i in b:\n",
        "          var.append([i])\n",
        "        b = tuple(var)\n",
        "\n",
        "      for iteration in range(self.niter):\n",
        "        \n",
        "        # Weighted sum of inputs / weights\n",
        "        weighted_sum = np.dot(a, weights)\n",
        "        \n",
        "        # Activate!\n",
        "        activated_output = self.sigmoid(weighted_sum)\n",
        "        \n",
        "        # Cac error\n",
        "        error = b - activated_output\n",
        "        \n",
        "        adjustments = error * self.sigmoid_derivative(weighted_sum)\n",
        "        weights += np.dot(a.T, adjustments)\n",
        "        \n",
        "        # Update the Weights\n",
        "      # weights += np.dot(a.T, adjustments)\n",
        "      return activated_output\n",
        "\n",
        "    def predict(self):\n",
        "      predictions = []\n",
        "      for i in self.fit():\n",
        "        predictions.append(round(i[0], 2))\n",
        "      return predictions\n",
        "\n",
        "\n",
        "percept = Perceptron(inputs, correct_outputs)\n",
        "#percept = Perceptron(input, output)\n",
        "percept.fit()\n",
        "percept.predict()\n",
        "# Can't figure out why it works fine on inputs/correct_outputs\n",
        "# But is completely useless on everything else."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03, 0.97, 0.98, 0.03, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ka9xdoONGz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3bd078a0-9735-45ba-b111-df249407b294"
      },
      "source": [
        "percept = Perceptron(input, output)\n",
        "percept.predict()\n",
        "# For example, this is absolutely useless."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fj513SYT-u4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e003111-7d47-4c40-c19c-b0dc6acf6a44"
      },
      "source": [
        "inputs = np.array([[0,0,1],\n",
        "                   [1,1,1],\n",
        "                   [1,0,1],\n",
        "                   [0,1,1],\n",
        "                   [1,0,0]])\n",
        "\n",
        "correct_outputs = ([0], [1], [1], [0], [1])\n",
        "\n",
        "precep = Perceptron(inputs, correct_outputs)\n",
        "precep"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Perceptron at 0x7f2c0a17dc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6QR4oAW1xdyu"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}